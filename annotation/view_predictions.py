#! /usr/bin/env/python3

"""
Visualise the predition results using a trained yolov8 weights file (ideally from a trained run)
For Mask predictions, also can label ground truth annotations on the image
"""

from ultralytics import YOLO
import os
import glob
import torch
import cv2 as cv
import numpy as np
from PIL import Image
from Utils import classes, class_colours, overlap_boxes, combine_detections, callback
import supervision as sv

ultralitics_version = False #set to true, if want example of ultralitics prediction
SAHI = False #set to true if using SAHI to look at 640p images
batch = True #image too big / too many predictions to do in one go

batch_height, batch_width = 3000, 3000
#weight_file = "/home/java/Java/ultralytics/runs/segment/train9/weights/cgras_yolov8n-seg_640p_20231209.pt" #dorian used
weights_file_path = '/media/wardlewo/cslics_ssd/SCU_Pdae_Data/split and tilling/ultralytics_output/train4/weights/best.pt' #trained on 640 imgsz dataset combined 22 and 23
#weights_file_path = "/home/java/Java/ultralytics/runs/segment/train21/weights/best.pt" #trained on 640 imgsz dataset combined 22 and 23
weights_file_path = "/home/java/hpc-home/runs/240p_v8m_results/weights/best.pt"

save_dir = '/media/wardlewo/cslics_ssd/SCU_Pdae_Data/testsAndVisualisation/20243110_Pdae_Visualisation'
img_folder = os.path.join('/media/wardlewo/cslics_ssd/SCU_Pdae_Data/split and tilling/test/images')
save_dir = '/media/java/CGRAS-SSD/cgras_data_copied_2240605/samples/cgras_data_copied_2240605_ultralytics_data/check_gt_UPDATED'
img_folder = os.path.join('/media/java/CGRAS-SSD/cgras_data_copied_2240605/samples/cgras_data_copied_2240605_ultralytics_data/images')
#txt_folder = os.path.join(save_dir, 'train', 'labels')
txt_folder = os.path.join('/media/wardlewo/cslics_ssd/SCU_Pdae_Data/split and tilling/test/labels')
txt_folder = os.path.join('/media/java/CGRAS-SSD/cgras_data_copied_2240605/samples/cgras_data_copied_2240605_ultralytics_data/labels')

#save txt results like they would be saved by ultralytics
def save_txt_predictions_masks(results, conf, class_list, save_path):
    """save_txt_predictions_masks
    writes a textfile for the segmentation results, saving the data as ultralytics does
    """
    masks = results[0].masks
    txt_results = []
    for i, r in enumerate(masks):
        txt_result1 = [int(class_list[i])]
        seg = masks[i].xyn[0].copy().reshape(-1)
        for j, s in enumerate(seg):
            txt_result1.append(seg[j])
        txt_result1.append(conf[i])
        txt_results.append(txt_result1)
    with open(save_path, 'w') as file:
        for txt_result in txt_results:
            for item in txt_result:
                file.write(str(item) + ' ')
            file.write('\n')

def add_ground_truth(image, txt, classes, class_colours, line_tickness, imgname):
    """add_ground_truth
    adds the ground truth annotiations onto an image. Assumed groundtruth is masks
    """
    height, width, _ = image.shape
    points_normalised, points, class_idx = [], [], []
    with open(txt, "r") as file:
        lines = file.readlines()
    for line in lines:
        data = line.strip().split()
        class_idx.append(int(data[0]))
        points_normalised.append([float(val) for val in data[1:]])
    for data in points_normalised:
        values = []
        try:
            for i in range(0, len(data), 2):
                x = round(data[i]*width)
                y = round(data[i+1]*height)
                values.extend([x,y])
            points.append(values)
        except:
            points.append(values)
            print(f'invalid line of data length: {len(data)}, related to img {imgname}')
    for idx in range(len(class_idx)):
        pointers = np.array(points[idx], np.int32).reshape(-1,2)
        cv.polylines(image, [pointers], True, class_colours[classes[class_idx[idx]]], line_tickness)
    # imgsave_path = os.path.join(save_dir, os.path.basename(imgname)[:-4] + '_gt.jpg')
    # cv.imwrite(imgsave_path, image)
    print(f'number of ground truth annotiations: {len(points)}')
    cls_name = classes[class_idx[idx]]
    try:
        cv.putText(image, f"{cls_name}", (int(np.min(pointers[:, 0])-20), int(np.min(pointers[:, 1]) - 5)), cv.FONT_HERSHEY_SIMPLEX, 3, class_colours[classes[class_idx[idx]]], 3)
    except:
        import code
        code.interact(local=dict(globals(), **locals()))
    return image

def save_image_predictions_mask(results, image, imgname, save_path, conf, class_list, classes, class_colours, ground_truth=False, txt=None):
    """save_image_predictions_mask
    saves the predicted masks results onto an image, recoring confidence and class as well. 
    Can also show ground truth anotiations from the associated textfile (assumed annotiations are normalised xy corifinate points)
    """
    height, width, _ = image.shape
    masked = image.copy()
    line_tickness = int(round(width)/600)
    font_size = 1#int(round(line_tickness/2))
    font_thickness = 1#3*(abs(line_tickness-font_size))+font_size
    if results and results[0].masks:
        for j, m in enumerate(results[0].masks):
            xyn = np.array(m.xyn)
            xyn[0, :, 0] = (xyn[0, :, 0] * width)
            xyn[0, :, 1] = (xyn[0, :, 1] * height)
            points = xyn.reshape((-1, 1, 2)).astype(np.int32)
            cls_name = classes[int(class_list[j])]
            desired_color = class_colours[cls_name]
            if points is None or not points.any() or len(points) == 0:
                print(f'mask {j} encountered problem with points {points}, class is {cls_name}')
            else: 
                cv.fillPoly(masked, [points], desired_color)
                xmin = min(xyn[0, :, 0])
                ymin = min(xyn[0, :, 1])
                cv.putText(image, f"{conf[j]:.2f}: {cls_name}", (int(xmin-20), int(ymin - 5)), cv.FONT_HERSHEY_SIMPLEX, font_size, desired_color, font_thickness)
    else:
        print(f'No masks found in {imgname}')
    
    if ground_truth & (txt is not None):
        image = plot_ground_truth(image, txt, classes, class_colours, line_tickness, imgname)        
        image = add_ground_truth(image, txt, classes, class_colours, line_tickness)

    alpha = 0.5
    semi_transparent_mask = cv.addWeighted(image, 1-alpha, masked, alpha, 0)
    imgsavename = os.path.basename(imgname)
    imgsave_path = os.path.join(save_dir, imgsavename[:-4] + '_det_mask.jpg')
    cv.imwrite(imgsave_path, semi_transparent_mask)

    # import code
    # code.interact(local=dict(globals(), **locals()))

def save_img_batch(image_cv, box_array, conf_list, cls_id_list, mask_list, image_name, save_dir):
    height, width, _ = image_cv.shape
    masked = image_cv.copy()
    line_tickness = int(round(width)/600)
    font_size = 2#int(round(line_tickness/2))
    font_thickness = 5#3*(abs(line_tickness-font_size))+font_size
    if conf_list is not None:
        for j, m in enumerate(mask_list):
            contours, _ = cv.findContours(m[0], cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE) 
            for contour in contours:
                points = np.squeeze(contour)
                if len(points.shape) == 1:
                    points = points.reshape(-1, 1, 2)
                elif len(points.shape) == 2 and points.shape[1] != 2:
                    points = points.reshape(-1, 1, 2)
                points += np.array([m[1], m[2]]) #shift the points to the correct location
                cls = classes[int(cls_id_list[j])]
                desired_color = class_colours[cls]
                if points is None or not points.any() or len(points) == 0:
                    print(f'mask {j} encountered problem with points {points}, class is {cls}')
                else: 
                    cv.fillPoly(masked, [points], desired_color) 
        for t, b in enumerate(box_array):
            cls = classes[int(cls_id_list[t])]
            desired_color = class_colours[cls]
            cv.putText(image_cv, f"{conf_list[t]:.2f}: {cls}", (int(b[0]-20), int(b[1] - 5)), cv.FONT_HERSHEY_SIMPLEX, font_size, desired_color, font_thickness)
    else:
        print(f'No masks found in {image_name}')
    alpha = 0.5
    semi_transparent_mask = cv.addWeighted(image_cv, 1-alpha, masked, alpha, 0)
    imgsavename = os.path.basename(image_name)
    imgsave_path = os.path.join(save_dir, imgsavename[:-4] + '_det_mask.jpg')
    cv.imwrite(imgsave_path, semi_transparent_mask)

def update_lists(box_list, conf_list, cls_id_list, mask_list, sliced_detections, x, y, x_end, y_end):
    for box in sliced_detections.xyxy:
        box[0] += x
        box[1] += y
        box[2] += x
        box[3] += y
        box_list.append(box)
    for conf in sliced_detections.confidence:
        conf_list.append(conf)
    for cls_id in sliced_detections.class_id:
        cls_id_list.append(cls_id)
    for data in sliced_detections.data['class_name']:
        data_dict['class_name'].append(data)
    for mask in sliced_detections.mask:
        mask_resized = cv.resize(mask.astype(np.uint8), (x_end - x, y_end - y))
        rows, cols = np.where(mask_resized == 1)
        if len(rows) > 0 and len(cols) > 0:
            top_left_y = rows.min()
            bottom_right_y = rows.max()
            top_left_x = cols.min()
            bottom_right_x = cols.max()
            box_width = bottom_right_x - top_left_x + 1
            box_height = bottom_right_y - top_left_y + 1
            sub_mask = mask_resized[top_left_y:bottom_right_y + 1, top_left_x:bottom_right_x + 1]
            mask_list.append((sub_mask, top_left_x + x, top_left_y + y, box_width, box_height))  
    return box_list, conf_list, cls_id_list, mask_list

def save_img_sliced(slicer, image, image_file, save_dir):
    sliced_detections = slicer(image=image)
    masked = image.copy()
    for detection in sliced_detections:
        xyxy = detection[0].tolist()
        mask_array = detection[1].astype(np.uint8) 
        confidence = detection[2]
        class_id = detection[3]
        contours, _ = cv.findContours(mask_array, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            points = np.squeeze(contour)
            if len(points.shape) == 1:
                points = points.reshape(-1, 1, 2)
            elif len(points.shape) == 2 and points.shape[1] != 2:
                points = points.reshape(-1, 1, 2)
            cls_name = classes[class_id]
            desired_color = class_colours[cls_name]
            if points is None or not points.any() or len(points) == 0:
                print(f'mask encountered problem with points {points}, class is {cls_name}')
            else: 
                cv.fillPoly(masked, [points], desired_color) 
        cv.putText(image, f"{confidence:.2f}: {cls_name}", (int(xyxy[0]-20), int(xyxy[1] - 5)), cv.FONT_HERSHEY_SIMPLEX, 2, desired_color, 5)
    alpha = 0.30
    semi_transparent_mask = cv.addWeighted(image, 1-alpha, masked, alpha, 0)
    imgsave_path = os.path.join(save_dir, os.path.basename(image_file)[:-4] + '_t1.jpg')
    cv.imwrite(imgsave_path, semi_transparent_mask)

# load model
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model = YOLO(weights_file_path).to(device)
slicer = sv.InferenceSlicer(callback=callback, slice_wh=(640, 640), overlap_ratio_wh=(0.1, 0.1))

print('Model Inference:')

imglist = sorted(glob.glob(os.path.join(img_folder, '*.jpg')))
txtlist = sorted(glob.glob(os.path.join(txt_folder, '*.txt')))
imgsave_dir = save_dir
os.makedirs(imgsave_dir, exist_ok=True)

if not ultralitics_version:
    for i, imgname in enumerate(imglist):
        print(f'predictions on {i+1}/{len(imglist)}')
        if i >= 500: # for debugging purposes
            break 
            import code
            code.interact(local=dict(globals(), **locals()))
        
        image = cv.imread(imgname)
        results = model.predict(source=imgname, iou=0.5, agnostic_nms=True, imgsz=640)
        conf, class_list = [], [] 
        for j, b in enumerate(results[0].boxes):
            conf.append(b.conf.item())
            class_list.append(b.cls.item())
        
        txt = txtlist[i]
        ground_truth = True
        save_image_predictions_mask(results, image, imgname, imgsave_dir, conf, class_list, classes, class_colours, ground_truth, txt)


if SAHI:
    for i, imgname in enumerate(imglist):
        print(f'SHAI predictions on {i+1}/{len(imglist)}')
        image = cv.imread(imgname)
        txt = txtlist[i]
        image_height, image_width = image.shape[:2]
        if batch:
            data_dict = {'class_name': []}
            box_list, conf_list, cls_id_list, mask_list = [], [], [], []
            print("Batching image")
            for y in range(0, image_height, batch_height):
                for x in range(0, image_width, batch_width):
                    y_end = min(y + batch_height, image_height)
                    x_end = min(x + batch_width, image_width)
                    img= image[y:y_end, x:x_end]
                    sliced_detections = slicer(image=img)
                    if sliced_detections.confidence.size == 0:
                        print("No detections found in batch")
                        continue
                    box_list, conf_list, cls_id_list, mask_list = update_lists(box_list, conf_list, cls_id_list, mask_list, sliced_detections, x, y, x_end, y_end)
            conf_array = np.array(conf_list)
            box_array = np.array(box_list)
            updated_box_array, updated_conf_list, updated_class_id, updated_mask_list, overlap_count = combine_detections(box_array, conf_array, cls_id_list, mask_list)
            while overlap_count > 1:
                conf_array = np.array(updated_conf_list)
                box_array = np.array(updated_box_array)
                print("update again")
                updated_box_array, updated_conf_list, updated_class_id, updated_mask_list, overlap_count = combine_detections(box_array, conf_array, updated_class_id, updated_mask_list)
            image2 = add_ground_truth(image, txt, classes, class_colours, 10, imgname)
            save_img_batch(image, updated_box_array, updated_conf_list, updated_class_id, updated_mask_list, os.path.basename(imgname), save_dir)
        else:
            image = add_ground_truth(image, txt, classes, class_colours, 2)
            save_img_sliced(slicer, image, imgname, save_dir)



if ultralitics_version: #ultralytics code
    ##Should have code, doesn't?
    print("ultralitics code")
elif not ultralitics_version:
    for i, imgname in enumerate(imglist):
        print(f'predictions on {i+1}/{len(imglist)}')
        image = cv.imread(imgname)

        txt = txtlist[i]
        # results = model.predict(source=imgname, iou=0.5, agnostic_nms=True, imgsz=640)
        # conf, class_list = [], [] 
        # for j, b in enumerate(results[0].boxes):
        #     conf.append(b.conf.item())
        #     class_list.append(b.cls.item())
        ground_truth = True
        #save_image_predictions_mask(results, image, imgname, imgsave_dir, conf, class_list, classes, class_colours, ground_truth, txt)
        image = add_ground_truth(image, txt, classes, class_colours, 4, imgname)
        imgsave_path = os.path.join(save_dir, os.path.basename(imgname)[:-4] + '_det_mask.jpg')
        cv.imwrite(imgsave_path, image)

        # import code
        # code.interact(local=dict(globals(), **locals()))

elif ultralitics_version: #ultralytics code
    for i, imgname in enumerate(imglist):
        image = cv.imread(imgname)
        results = model.predict(source=image, iou=0.5, agnostic_nms=True)
        conf = []
        class_list = []
        #masks = results[0].masks
        for i, b in enumerate(results[0].boxes):
            conf.append(b.conf.item())
            class_list.append(b.cls.item())
            #seg = masks[i].xyn[0]
        for r in results:
            im_array = r.plot(conf=True, line_width=4, font_size=4, boxes=True)
            im = Image.fromarray(im_array[..., ::-1])
            im.show()
        

# for interactive debugger in terminal:
print("for bounding boxes below")
import code
code.interact(local=dict(globals(), **locals()))

def save_image_predictions(results, image, imgname, save_path, classes, class_colours, ground_truth=False, txt=None):
    """save_image_predictions
    saves the predicted bb results onto an image, recoring confidence and class as well. 
    Can also show ground truth anotiations from the associated textfile (assumed annotiations are normalised xy corifinate points)
    """
    height, width, _ = image.shape
    line_tickness = int(round(width)/600)
    font_size = 1#int(round(line_tickness/2))
    font_thickness = 1#3*(abs(line_tickness-font_size))+font_size
    if results and results[0].boxes:
        for j, b in enumerate(results[0].boxes):
            x1, y1, x2, y2 = b.xyxy[0].tolist()
            cls_name = classes[int(b.cls_name.item())]
            desired_color = class_colours[cls_name]
            conf = b.conf.item()
            cv.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2),), desired_color, line_tickness*2)
            cv.putText(image, f"{conf:.2f}: {cls_name}", (int(x1), int(y1 - 5)), cv.FONT_HERSHEY_SIMPLEX, font_size, desired_color, font_thickness)
    else:
        print(f'No boxes found in {imgname}')
    if ground_truth & (txt is not None):
        with open(txt, "r") as file:
            lines = file.readlines()
        for line in lines:
            data = line.strip().split()
            cls_name = classes[int(data[0])]
            desired_color = class_colours[cls_name]
            x1 = int(float(data[1])*width)
            y1 = int(float(data[2])*height)
            w = int(float(data[3])*width)
            h = int(float(data[4])*height)
            cv.rectangle(image, (x1-w, y1-h), (x1+h, y1+w), desired_color, line_tickness)
            cv.putText(image, f"{cls_name}", (x1, y1 - 5), cv.FONT_HERSHEY_SIMPLEX, font_size, desired_color, font_thickness)
    imgsavename = os.path.basename(imgname)
    imgsave_path = os.path.join(save_path, imgsavename[:-4] + '_det.jpg')
    cv.imwrite(imgsave_path, image)

for i, imgname in enumerate(imglist):
        print(f'predictions on {i+1}/{len(imglist)}')
        #if i >= 10: # for debugging purposes
        #    break 
        #    import code
        #    code.interact(local=dict(globals(), **locals()))
        image = cv.imread(imgname)
        results = model.predict(source=imgname, iou=0.5, agnostic_nms=True, imgsz=640)
        
        results = []
        
        txt = txtlist[i]
        ground_truth = True
        save_image_predictions(results, image, imgname, imgsave_dir, classes, class_colours,  ground_truth, txt)